{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "135168c6",
   "metadata": {},
   "source": [
    "# 为long-format文件添加临床信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00353caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "411b2992",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =========================\n",
    "# 0) EDIT HERE\n",
    "# =========================\n",
    "TNB_RANK_LONG_CSV = \"/work/longyh/BY/processed/TNB/rank/TNB_rank_long.csv\"  # rank版 long\n",
    "CLINICAL_XLSX     = \"/work/longyh/BY/raw/1-s2.0-S0092867417311224-mmc2.xlsx\"\n",
    "\n",
    "OUT_LONG_CSV      = \"/work/longyh/BY/processed/TNB/rank/tnb_rank_long_with_clinical.csv\"\n",
    "\n",
    "# 可选：只保留哪些策略 / 哪些metric\n",
    "KEEP_STRATEGY = [\"s1_rank\", \"s2_rank\", \"s3_rank\", \"s4_rank\"]   # 若也要 total，可加 \"total\"\n",
    "KEEP_WHICH    = [\"unique\"]                                    # or [\"raw\",\"unique\"]\n",
    "KEEP_UNIT     = [\"mutation\"]                                  # 主分析；附录再加 [\"peptide\",\"hla_peptide\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5781e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def make_response_label(df, response_col=\"Response\"):\n",
    "    \"\"\"\n",
    "    Make response_label: CR/PR=1, SD/PD=0; remove NE.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df[df[response_col].notna()]\n",
    "    df[response_col] = df[response_col].astype(str).str.strip().str.upper()\n",
    "    df = df[df[response_col] != \"NE\"].copy()\n",
    "\n",
    "    response_map = {\"CR\": 1, \"PR\": 1, \"SD\": 0, \"PD\": 0}\n",
    "    df[\"response_label\"] = df[response_col].map(response_map)\n",
    "\n",
    "    unknown = df.loc[df[\"response_label\"].isna(), response_col].value_counts()\n",
    "    if len(unknown) > 0:\n",
    "        print(\"[WARN] Unmapped Response categories:\\n\", unknown)\n",
    "        df = df.dropna(subset=[\"response_label\"]).copy()\n",
    "\n",
    "    df[\"response_label\"] = df[\"response_label\"].astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feca1bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 1) Load\n",
    "# -------------------------\n",
    "tnb = pd.read_csv(TNB_RANK_LONG_CSV, dtype=str)\n",
    "clinical = pd.read_excel(CLINICAL_XLSX, skiprows=2)\n",
    "\n",
    "# sanity check\n",
    "required = {\"sample\", \"unit\", \"strategy\", \"metric\", \"value\"}\n",
    "missing = required - set(tnb.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in rank long CSV: {missing}\")\n",
    "\n",
    "# normalize keys\n",
    "tnb[\"sample\"] = tnb[\"sample\"].astype(str).str.strip()\n",
    "clinical[\"Patient\"] = clinical[\"Patient\"].astype(str).str.strip()\n",
    "\n",
    "# numeric\n",
    "tnb[\"value\"] = pd.to_numeric(tnb[\"value\"], errors=\"coerce\")\n",
    "\n",
    "# clinical: response label + drop NE\n",
    "clinical2 = make_response_label(clinical, response_col=\"Response\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24bae0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged rows = 440\n",
      "Merged unique samples = 22\n",
      "Responders = 6 / 22\n",
      "Final long-format rows = 88\n",
      "   sample      unit strategy  \\\n",
      "3    Pt10  mutation  s1_rank   \n",
      "5    Pt10  mutation  s2_rank   \n",
      "7    Pt10  mutation  s3_rank   \n",
      "9    Pt10  mutation  s4_rank   \n",
      "23   Pt11  mutation  s1_rank   \n",
      "25   Pt11  mutation  s2_rank   \n",
      "27   Pt11  mutation  s3_rank   \n",
      "29   Pt11  mutation  s4_rank   \n",
      "43   Pt18  mutation  s1_rank   \n",
      "45   Pt18  mutation  s2_rank   \n",
      "\n",
      "                                        strategy_name   which  tnb_value  \\\n",
      "3                            Binding-only (%Rank<2.0)  unique         47   \n",
      "5                                   %Rank<2.0 & TPM>1  unique         39   \n",
      "7                                   %Rank<0.5 & TPM>5  unique         20   \n",
      "9   High-quality (%Rank<0.5,TPM>5,VAF>0.1,WT%Rank>...  unique          1   \n",
      "23                           Binding-only (%Rank<2.0)  unique         28   \n",
      "25                                  %Rank<2.0 & TPM>1  unique         20   \n",
      "27                                  %Rank<0.5 & TPM>5  unique          8   \n",
      "29  High-quality (%Rank<0.5,TPM>5,VAF>0.1,WT%Rank>...  unique          2   \n",
      "43                           Binding-only (%Rank<2.0)  unique         54   \n",
      "45                                  %Rank<2.0 & TPM>1  unique         45   \n",
      "\n",
      "   Patient Response  response_label  Mutation Load  Neo-antigen Load  \\\n",
      "3     Pt10       SD               0           75.0              33.0   \n",
      "5     Pt10       SD               0           75.0              33.0   \n",
      "7     Pt10       SD               0           75.0              33.0   \n",
      "9     Pt10       SD               0           75.0              33.0   \n",
      "23    Pt11       PD               0          106.0              67.0   \n",
      "25    Pt11       PD               0          106.0              67.0   \n",
      "27    Pt11       PD               0          106.0              67.0   \n",
      "29    Pt11       PD               0          106.0              67.0   \n",
      "43    Pt18       PR               1          217.0             137.0   \n",
      "45    Pt18       PR               1          217.0             137.0   \n",
      "\n",
      "    Neo-peptide Load  Cytolytic Score  Dead/Alive\\n(Dead = True)  \\\n",
      "3               56.0        65.840717                       True   \n",
      "5               56.0        65.840717                       True   \n",
      "7               56.0        65.840717                       True   \n",
      "9               56.0        65.840717                       True   \n",
      "23             187.0       602.674041                       True   \n",
      "25             187.0       602.674041                       True   \n",
      "27             187.0       602.674041                       True   \n",
      "29             187.0       602.674041                       True   \n",
      "43             311.0       907.568179                      False   \n",
      "45             311.0       907.568179                      False   \n",
      "\n",
      "    Time to Death\\n(weeks)      Cohort  \\\n",
      "3                36.571429  NIV3-NAIVE   \n",
      "5                36.571429  NIV3-NAIVE   \n",
      "7                36.571429  NIV3-NAIVE   \n",
      "9                36.571429  NIV3-NAIVE   \n",
      "23              119.571429  NIV3-NAIVE   \n",
      "25              119.571429  NIV3-NAIVE   \n",
      "27              119.571429  NIV3-NAIVE   \n",
      "29              119.571429  NIV3-NAIVE   \n",
      "43              153.285714  NIV3-NAIVE   \n",
      "45              153.285714  NIV3-NAIVE   \n",
      "\n",
      "                                        file  \n",
      "3   Pt10_tumor.MHC_I.all_epitopes.TPM.QC.tsv  \n",
      "5   Pt10_tumor.MHC_I.all_epitopes.TPM.QC.tsv  \n",
      "7   Pt10_tumor.MHC_I.all_epitopes.TPM.QC.tsv  \n",
      "9   Pt10_tumor.MHC_I.all_epitopes.TPM.QC.tsv  \n",
      "23  Pt11_tumor.MHC_I.all_epitopes.TPM.QC.tsv  \n",
      "25  Pt11_tumor.MHC_I.all_epitopes.TPM.QC.tsv  \n",
      "27  Pt11_tumor.MHC_I.all_epitopes.TPM.QC.tsv  \n",
      "29  Pt11_tumor.MHC_I.all_epitopes.TPM.QC.tsv  \n",
      "43  Pt18_tumor.MHC_I.all_epitopes.TPM.QC.tsv  \n",
      "45  Pt18_tumor.MHC_I.all_epitopes.TPM.QC.tsv  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------\n",
    "# 2) Merge (inner join = keep samples with clinical labels)\n",
    "# -------------------------\n",
    "merged = pd.merge(\n",
    "    tnb,\n",
    "    clinical2,\n",
    "    left_on=\"sample\",\n",
    "    right_on=\"Patient\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"Merged rows =\", len(merged))\n",
    "print(\"Merged unique samples =\", merged[\"sample\"].nunique())\n",
    "print(\"Responders =\", int(merged.drop_duplicates(\"sample\")[\"response_label\"].sum()),\n",
    "      \"/\", merged[\"sample\"].nunique())\n",
    "\n",
    "# -------------------------\n",
    "# 3) Convert to legacy column names for plotting compatibility\n",
    "#    (so you can keep your old plotting script almost unchanged)\n",
    "# -------------------------\n",
    "merged = merged.rename(columns={\"metric\": \"which\", \"value\": \"tnb_value\"})\n",
    "merged[\"which\"] = merged[\"which\"].astype(str).str.strip()\n",
    "merged[\"strategy\"] = merged[\"strategy\"].astype(str).str.strip()\n",
    "merged[\"unit\"] = merged[\"unit\"].astype(str).str.strip()\n",
    "\n",
    "# optional: filter\n",
    "if KEEP_STRATEGY is not None:\n",
    "    merged = merged[merged[\"strategy\"].isin(KEEP_STRATEGY)].copy()\n",
    "if KEEP_WHICH is not None:\n",
    "    merged = merged[merged[\"which\"].isin(KEEP_WHICH)].copy()\n",
    "if KEEP_UNIT is not None:\n",
    "    merged = merged[merged[\"unit\"].isin(KEEP_UNIT)].copy()\n",
    "\n",
    "# optional: add strategy_name for rank version\n",
    "strategy_map = {\n",
    "    \"s1_rank\": \"Binding-only (%Rank<2.0)\",\n",
    "    \"s2_rank\": \"%Rank<2.0 & TPM>1\",\n",
    "    \"s3_rank\": \"%Rank<0.5 & TPM>5\",\n",
    "    \"s4_rank\": \"High-quality (%Rank<0.5,TPM>5,VAF>0.1,WT%Rank>2.0)\",\n",
    "    \"total\": \"Total candidates\",\n",
    "}\n",
    "merged[\"strategy_name\"] = merged[\"strategy\"].map(strategy_map).fillna(merged[\"strategy\"])\n",
    "\n",
    "# -------------------------\n",
    "# 4) Keep only clinical cols you care about (optional)\n",
    "# -------------------------\n",
    "keep_cols = [\n",
    "    # core ids / outcome\n",
    "    \"sample\", \"Patient\", \"Response\", \"response_label\",\n",
    "    # covariates / endpoints (use your existing names if present)\n",
    "    \"Mutation Load\", \"Neo-antigen Load\", \"Neo-peptide Load\", \"Cytolytic Score\",\n",
    "    \"Dead/Alive\\n(Dead = True)\", \"Time to Death\\n(weeks)\",\n",
    "    \"Cohort\",\n",
    "]\n",
    "\n",
    "# keep only those that actually exist\n",
    "keep_cols = [c for c in keep_cols if c in merged.columns]\n",
    "\n",
    "final_cols = (\n",
    "    [\"sample\", \"unit\", \"strategy\", \"strategy_name\", \"which\", \"tnb_value\"]\n",
    "    + keep_cols\n",
    "    + [\"file\"] if \"file\" in merged.columns else []\n",
    ")\n",
    "\n",
    "# de-dup any repeats in final_cols while preserving order\n",
    "seen = set()\n",
    "final_cols2 = []\n",
    "for c in final_cols:\n",
    "    if c not in seen and c in merged.columns:\n",
    "        final_cols2.append(c)\n",
    "        seen.add(c)\n",
    "\n",
    "out = merged[final_cols2].copy()\n",
    "\n",
    "print(\"Final long-format rows =\", len(out))\n",
    "print(out.head(10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97e5fd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /work/longyh/BY/processed/TNB/rank/tnb_rank_long_with_clinical.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 5) Save\n",
    "# -------------------------\n",
    "out.to_csv(OUT_LONG_CSV, index=False)\n",
    "print(\"Saved:\", OUT_LONG_CSV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42663be",
   "metadata": {},
   "source": [
    "# 绘制ROC和KM图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bccac60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/longyh/miniforge3/envs/py310/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# lifelines for KM/Cox\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from lifelines.statistics import logrank_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1975d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 0) EDIT HERE\n",
    "# =========================\n",
    "LONG_CSV = \"/work/longyh/BY/processed/TNB/rank/tnb_rank_long_with_clinical.csv\"  # 你的long-format文件\n",
    "OUTDIR = \"/work/longyh/BY/plots\"\n",
    "COHORT_LABEL = \"Ipi-N\"  # 纯标签：不依赖临床Cohort列\n",
    "FILTER_WHICH = [\"unique\"]  # 可改成 [\"unique\"] 或 [\"raw\",\"unique\"]\n",
    "FILTER_STRATEGY = [\"s1_rank\", \"s2_rank\", \"s3_rank\", \"s4_rank\"]  # 可选：只跑 [\"s1\"]\n",
    "FILTER_UNIT = [\"mutation\", \"peptide\"]\n",
    "N_BOOT = 2000\n",
    "SEED = 1\n",
    "\n",
    "# 是否保存图片\n",
    "SAVE_PLOTS = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "440a48cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1) Helpers\n",
    "# =========================\n",
    "def ensure_response_label(df):\n",
    "    \"\"\"\n",
    "    Ensure response_label exists: CR/PR=1, SD/PD=0, NE removed.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if \"response_label\" in df.columns and df[\"response_label\"].notna().any():\n",
    "        # make sure int\n",
    "        df = df.dropna(subset=[\"response_label\"])\n",
    "        df[\"response_label\"] = df[\"response_label\"].astype(int)\n",
    "        return df\n",
    "\n",
    "    if \"Response\" not in df.columns:\n",
    "        raise ValueError(\"Neither response_label nor Response column found.\")\n",
    "\n",
    "    d = df.copy()\n",
    "    d[\"Response\"] = d[\"Response\"].astype(str).str.strip().str.upper()\n",
    "    d = d[d[\"Response\"] != \"NE\"].copy()\n",
    "    mp = {\"CR\": 1, \"PR\": 1, \"SD\": 0, \"PD\": 0}\n",
    "    d[\"response_label\"] = d[\"Response\"].map(mp)\n",
    "    unknown = d.loc[d[\"response_label\"].isna(), \"Response\"].value_counts()\n",
    "    if len(unknown) > 0:\n",
    "        print(\"[WARN] Unmapped Response categories:\\n\", unknown)\n",
    "        d = d.dropna(subset=[\"response_label\"]).copy()\n",
    "    d[\"response_label\"] = d[\"response_label\"].astype(int)\n",
    "    return d\n",
    "\n",
    "\n",
    "def bootstrap_auc_ci(y_true, y_score, n_boot=2000, seed=1):\n",
    "    \"\"\"\n",
    "    Bootstrap percentile CI for AUC.\n",
    "    Skips resamples with single class.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    y_true = np.asarray(y_true, dtype=int)\n",
    "    y_score = np.asarray(y_score, dtype=float)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    auc_point = auc(fpr, tpr)\n",
    "\n",
    "    boot = []\n",
    "    n = len(y_true)\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "        yt = y_true[idx]\n",
    "        ys = y_score[idx]\n",
    "        if len(np.unique(yt)) < 2:\n",
    "            continue\n",
    "        fpr_b, tpr_b, _ = roc_curve(yt, ys)\n",
    "        boot.append(auc(fpr_b, tpr_b))\n",
    "\n",
    "    if len(boot) < 50:\n",
    "        return float(auc_point), np.nan, np.nan, len(boot)\n",
    "\n",
    "    lo, hi = np.quantile(boot, [0.025, 0.975])\n",
    "    return float(auc_point), float(lo), float(hi), len(boot)\n",
    "\n",
    "\n",
    "def safe_filename(s: str) -> str:\n",
    "    s = str(s)\n",
    "    s = re.sub(r\"[^\\w\\-.]+\", \"_\", s)\n",
    "    return s[:200]\n",
    "\n",
    "\n",
    "def find_time_event_cols(df):\n",
    "    \"\"\"\n",
    "    Prefer PFS if columns exist; else OS using:\n",
    "      Time to Death (weeks) + Dead=True\n",
    "    \"\"\"\n",
    "    cols = list(df.columns)\n",
    "\n",
    "    # Look for any plausible PFS\n",
    "    pfs_time_candidates = [c for c in cols if re.search(r\"\\bPFS\\b|progression\", str(c), flags=re.I)]\n",
    "    pfs_event_candidates = [c for c in cols if re.search(r\"event|status|progress\", str(c), flags=re.I)]\n",
    "\n",
    "    # heuristics: time column should contain 'week' or 'time'\n",
    "    time_col = None\n",
    "    event_col = None\n",
    "    for c in pfs_time_candidates:\n",
    "        if re.search(r\"week|time\", str(c), flags=re.I):\n",
    "            time_col = c\n",
    "            break\n",
    "    for c in pfs_event_candidates:\n",
    "        if re.search(r\"event|status\", str(c), flags=re.I):\n",
    "            event_col = c\n",
    "            break\n",
    "\n",
    "    if time_col and event_col:\n",
    "        return time_col, event_col, \"PFS\"\n",
    "\n",
    "    # fallback to your known OS columns\n",
    "    os_time = \"Time to Death\\n(weeks)\" if \"Time to Death\\n(weeks)\" in cols else None\n",
    "    os_event = \"Dead/Alive\\n(Dead = True)\" if \"Dead/Alive\\n(Dead = True)\" in cols else None\n",
    "    if os_time and os_event:\n",
    "        return os_time, os_event, \"OS\"\n",
    "\n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "def to_event01(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    if isinstance(x, (bool, np.bool_)):\n",
    "        return int(bool(x))\n",
    "    s = str(x).strip().lower()\n",
    "    if s in {\"true\", \"1\", \"dead\", \"yes\", \"event\"}:\n",
    "        return 1\n",
    "    if s in {\"false\", \"0\", \"alive\", \"no\", \"censored\", \"none\"}:\n",
    "        return 0\n",
    "    try:\n",
    "        v = int(float(s))\n",
    "        return 1 if v != 0 else 0\n",
    "    except Exception:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60e6789f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Columns in LONG_CSV: ['sample', 'unit', 'strategy', 'strategy_name', 'which', 'tnb_value', 'Patient', 'Response', 'response_label', 'Mutation Load', 'Neo-antigen Load', 'Neo-peptide Load', 'Cytolytic Score', 'Dead/Alive\\n(Dead = True)', 'Time to Death\\n(weeks)', 'Cohort', 'file']\n",
      "Long-format usable rows: 88\n",
      "Unique samples: 22\n",
      "Responders: 6 / 22\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 2) Load long-format (compat: old vs rank)\n",
    "# =========================\n",
    "df = pd.read_csv(LONG_CSV)\n",
    "\n",
    "print(\"[INFO] Columns in LONG_CSV:\", list(df.columns))\n",
    "\n",
    "# Case A: rank-long schema: sample,unit,strategy,metric,value\n",
    "if {\"sample\", \"unit\", \"strategy\", \"metric\", \"value\"}.issubset(df.columns):\n",
    "    df[\"sample\"] = df[\"sample\"].astype(str).str.strip()\n",
    "    df[\"unit\"] = df[\"unit\"].astype(str).str.strip()\n",
    "    df[\"strategy\"] = df[\"strategy\"].astype(str).str.strip()\n",
    "    df[\"metric\"] = df[\"metric\"].astype(str).str.strip()\n",
    "    df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "\n",
    "    # map to legacy names used by your plotting code\n",
    "    df = df.rename(columns={\"metric\": \"which\", \"value\": \"tnb_value\"})\n",
    "\n",
    "# Case B: legacy schema already: sample,unit,strategy,which,tnb_value\n",
    "elif {\"sample\", \"unit\", \"strategy\", \"which\", \"tnb_value\"}.issubset(df.columns):\n",
    "    df[\"sample\"] = df[\"sample\"].astype(str).str.strip()\n",
    "    df[\"unit\"] = df[\"unit\"].astype(str).str.strip()\n",
    "    df[\"strategy\"] = df[\"strategy\"].astype(str).str.strip()\n",
    "    df[\"which\"] = df[\"which\"].astype(str).str.strip()\n",
    "    df[\"tnb_value\"] = pd.to_numeric(df[\"tnb_value\"], errors=\"coerce\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"Unrecognized long-format schema. Need either \"\n",
    "        \"{sample,unit,strategy,metric,value} or {sample,unit,strategy,which,tnb_value}.\"\n",
    "    )\n",
    "\n",
    "# ---- from here, keep your original logic ----\n",
    "# drop strategy == \"total\" if you only want s1~s4 plots\n",
    "# (only apply this if those strategy names exist)\n",
    "keep_strats = [s for s in [\"s1_rank\", \"s2_rank\", \"s3_rank\", \"s4_rank\"] if s in set(df[\"strategy\"])]\n",
    "if keep_strats:\n",
    "    df = df[df[\"strategy\"].isin(keep_strats)].copy()\n",
    "\n",
    "# add/ensure response_label and drop NE\n",
    "df = ensure_response_label(df)\n",
    "df = df.dropna(subset=[\"tnb_value\"]).copy()\n",
    "\n",
    "# optional filters (use your original variables)\n",
    "df = df[df[\"which\"].isin(FILTER_WHICH)].copy()\n",
    "df = df[df[\"strategy\"].isin(FILTER_STRATEGY)].copy()\n",
    "df = df[df[\"unit\"].isin(FILTER_UNIT)].copy()\n",
    "\n",
    "print(\"Long-format usable rows:\", len(df))\n",
    "print(\"Unique samples:\", df[\"sample\"].nunique())\n",
    "print(\"Responders:\", int(df.drop_duplicates(\"sample\")[\"response_label\"].sum()), \"/\", df[\"sample\"].nunique())\n",
    "\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8d29620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: auc_summary_long.csv\n",
      "       unit strategy   which   n  responders       auc    ci_low   ci_high  \\\n",
      "0  mutation  s1_rank  unique  22           6  0.562500  0.199444  0.894787   \n",
      "1  mutation  s2_rank  unique  22           6  0.546875  0.221930  0.868638   \n",
      "3  mutation  s4_rank  unique  22           6  0.541667  0.208333  0.846300   \n",
      "2  mutation  s3_rank  unique  22           6  0.536458  0.210526  0.847115   \n",
      "\n",
      "   boot_kept  suggest_flip  \n",
      "0       1997         False  \n",
      "1       1997         False  \n",
      "3       1997         False  \n",
      "2       1997         False  \n",
      "Saved: auc_heatmap_table_unique.csv\n",
      "Saved: auc_heatmap_table_ci_unique.csv\n",
      "Saved: auc_heatmap_table_ciwidth_unique.csv\n",
      "Saved: /work/longyh/BY/plots/AUC_heatmap_Ipi-N_unique.png\n",
      "Saved: /work/longyh/BY/plots/AUC_heatmap_CIwidth_Ipi-N_unique.png\n",
      "[INFO] Using endpoint=OS | time_col=Time to Death\n",
      "(weeks) | event_col=Dead/Alive\n",
      "(Dead = True)\n",
      "KM usable samples: 22\n",
      "Saved: km_cox_summary_long.csv\n",
      "       unit strategy   which endpoint   n  events  median_cut  logrank_p  \\\n",
      "0  mutation  s1_rank  unique       OS  22      15        45.5   0.927424   \n",
      "1  mutation  s2_rank  unique       OS  22      15        36.0   0.594008   \n",
      "2  mutation  s3_rank  unique       OS  22      15        22.0   0.272580   \n",
      "3  mutation  s4_rank  unique       OS  22      15         2.0   0.798026   \n",
      "\n",
      "   cox_hr_log1p  cox_ci_low  cox_ci_high     cox_p  \n",
      "0      1.250865    0.683988     2.287559  0.467374  \n",
      "1      1.182274    0.676720     2.065509  0.556402  \n",
      "2      1.162720    0.676778     1.997581  0.585056  \n",
      "3      0.945241    0.507313     1.761203  0.859223  \n",
      "Done. Plots saved to: /work/longyh/BY/plots\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# =========================\n",
    "# 3) AUC loop + ROC plots\n",
    "# =========================\n",
    "auc_rows = []\n",
    "\n",
    "group_cols = [\"unit\", \"strategy\", \"which\"]\n",
    "for (unit, strategy, which), g in df.groupby(group_cols):\n",
    "    # g is multiple rows across samples; each sample should appear once per (unit,strategy,which)\n",
    "    # If duplicates exist, keep first and warn\n",
    "    gg = g.sort_values(\"sample\").drop_duplicates(subset=[\"sample\"])\n",
    "    y = gg[\"response_label\"].astype(int).values\n",
    "    x = gg[\"tnb_value\"].astype(float).values\n",
    "\n",
    "    # skip invalid\n",
    "    if len(gg) < 8 or len(np.unique(y)) < 2:\n",
    "        auc_rows.append({\n",
    "            \"unit\": unit, \"strategy\": strategy, \"which\": which,\n",
    "            \"n\": int(len(gg)),\n",
    "            \"responders\": int(y.sum()),\n",
    "            \"auc\": np.nan, \"ci_low\": np.nan, \"ci_high\": np.nan,\n",
    "            \"boot_kept\": 0,\n",
    "            \"suggest_flip\": np.nan,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    auc_point, ci_low, ci_high, boot_kept = bootstrap_auc_ci(y, x, n_boot=N_BOOT, seed=SEED)\n",
    "\n",
    "    # quick direction hint (not auto flipping)\n",
    "    auc_rev, _, _, _ = bootstrap_auc_ci(y, -x, n_boot=500, seed=SEED)\n",
    "    suggest_flip = bool(auc_point < 0.5 and auc_rev > auc_point)\n",
    "\n",
    "    auc_rows.append({\n",
    "        \"unit\": unit, \"strategy\": strategy, \"which\": which,\n",
    "        \"n\": int(len(gg)),\n",
    "        \"responders\": int(y.sum()),\n",
    "        \"auc\": float(auc_point),\n",
    "        \"ci_low\": float(ci_low) if not np.isnan(ci_low) else np.nan,\n",
    "        \"ci_high\": float(ci_high) if not np.isnan(ci_high) else np.nan,\n",
    "        \"boot_kept\": int(boot_kept),\n",
    "        \"suggest_flip\": suggest_flip,\n",
    "    })\n",
    "\n",
    "    # ROC plot\n",
    "    fpr, tpr, _ = roc_curve(y, x)\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    ci_text = \"CI unavailable\" if np.isnan(ci_low) else f\"95%CI [{ci_low:.3f}, {ci_high:.3f}]\"\n",
    "    flip_text = \" (maybe flip sign)\" if suggest_flip else \"\"\n",
    "    plt.title(f\"[{COHORT_LABEL}] {unit}-{strategy}-{which}\\nAUC={auc_point:.3f}, {ci_text}{flip_text}\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if SAVE_PLOTS:\n",
    "        fn = safe_filename(f\"ROC_{COHORT_LABEL}_{unit}_{strategy}_{which}.png\")\n",
    "        plt.savefig(os.path.join(OUTDIR, fn), dpi=200)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "auc_summary = pd.DataFrame(auc_rows).sort_values([\"auc\"], ascending=False)\n",
    "auc_summary.to_csv(\"/work/longyh/BY/processed/TNB/auc_summary_long.csv\", index=False)\n",
    "print(\"Saved: auc_summary_long.csv\")\n",
    "print(auc_summary.head(20))\n",
    "# =========================\n",
    "# 3.5) AUC heatmap tables + plots\n",
    "# =========================\n",
    "def plot_heatmap(matrix_df, title, xlabel, ylabel, out_png):\n",
    "    \"\"\"\n",
    "    Simple matplotlib heatmap for a pivot table (values numeric).\n",
    "    \"\"\"\n",
    "    # ensure order\n",
    "    mat = matrix_df.copy()\n",
    "\n",
    "    plt.figure(figsize=(1.2 * max(4, mat.shape[1] + 1), 1.0 * max(3, mat.shape[0] + 1)))\n",
    "    im = plt.imshow(mat.values, aspect=\"auto\")\n",
    "\n",
    "    plt.xticks(range(mat.shape[1]), mat.columns, rotation=30, ha=\"right\")\n",
    "    plt.yticks(range(mat.shape[0]), mat.index)\n",
    "\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.ax.set_ylabel(\"Value\", rotation=270, labelpad=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=220)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# 只用“有auc”的行\n",
    "auc_ok = auc_summary.dropna(subset=[\"auc\"]).copy()\n",
    "\n",
    "# 生成每个 which 一张热图（如果你只跑 unique，这里也只会出一张）\n",
    "for which in sorted(auc_ok[\"which\"].unique()):\n",
    "    sub = auc_ok[auc_ok[\"which\"] == which].copy()\n",
    "\n",
    "    # AUC pivot\n",
    "    auc_pivot = sub.pivot_table(\n",
    "        index=\"strategy\",\n",
    "        columns=\"unit\",\n",
    "        values=\"auc\",\n",
    "        aggfunc=\"mean\"\n",
    "    ).reindex(index=FILTER_STRATEGY, columns=FILTER_UNIT)\n",
    "\n",
    "    auc_pivot.to_csv(f\"auc_heatmap_table_{which}.csv\")\n",
    "    print(f\"Saved: auc_heatmap_table_{which}.csv\")\n",
    "\n",
    "    # AUC with CI string pivot (nice for tables)\n",
    "    sub[\"auc_ci_str\"] = sub.apply(\n",
    "        lambda r: (\n",
    "            f\"{r['auc']:.3f} [{r['ci_low']:.3f}, {r['ci_high']:.3f}]\"\n",
    "            if pd.notna(r[\"ci_low\"]) and pd.notna(r[\"ci_high\"])\n",
    "            else f\"{r['auc']:.3f} [NA]\"\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    auc_ci_pivot = sub.pivot_table(\n",
    "        index=\"strategy\",\n",
    "        columns=\"unit\",\n",
    "        values=\"auc_ci_str\",\n",
    "        aggfunc=\"first\"\n",
    "    ).reindex(index=FILTER_STRATEGY, columns=FILTER_UNIT)\n",
    "\n",
    "    auc_ci_pivot.to_csv(f\"/work/longyh/BY/processed/TNB/auc_heatmap_table_ci_{which}.csv\")\n",
    "    print(f\"Saved: auc_heatmap_table_ci_{which}.csv\")\n",
    "\n",
    "    # CI width heatmap (stability proxy)\n",
    "    sub[\"ci_width\"] = sub[\"ci_high\"] - sub[\"ci_low\"]\n",
    "    ciw_pivot = sub.pivot_table(\n",
    "        index=\"strategy\",\n",
    "        columns=\"unit\",\n",
    "        values=\"ci_width\",\n",
    "        aggfunc=\"mean\"\n",
    "    ).reindex(index=FILTER_STRATEGY, columns=FILTER_UNIT)\n",
    "\n",
    "    ciw_pivot.to_csv(f\"/work/longyh/BY/processed/TNB/auc_heatmap_table_ciwidth_{which}.csv\")\n",
    "    print(f\"Saved: auc_heatmap_table_ciwidth_{which}.csv\")\n",
    "\n",
    "    # Plot heatmaps\n",
    "    if SAVE_PLOTS:\n",
    "        out_auc = os.path.join(\n",
    "            OUTDIR,\n",
    "            safe_filename(f\"AUC_heatmap_{COHORT_LABEL}_{which}.png\")\n",
    "        )\n",
    "        plot_heatmap(\n",
    "            auc_pivot,\n",
    "            title=f\"[{COHORT_LABEL}] AUC heatmap ({which})\",\n",
    "            xlabel=\"Counting unit\",\n",
    "            ylabel=\"Strategy\",\n",
    "            out_png=out_auc\n",
    "        )\n",
    "        print(\"Saved:\", out_auc)\n",
    "\n",
    "        out_ciw = os.path.join(\n",
    "            OUTDIR,\n",
    "            safe_filename(f\"AUC_heatmap_CIwidth_{COHORT_LABEL}_{which}.png\")\n",
    "        )\n",
    "        plot_heatmap(\n",
    "            ciw_pivot,\n",
    "            title=f\"[{COHORT_LABEL}] AUC CI width heatmap ({which})\",\n",
    "            xlabel=\"Counting unit\",\n",
    "            ylabel=\"Strategy\",\n",
    "            out_png=out_ciw\n",
    "        )\n",
    "        print(\"Saved:\", out_ciw)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 4) KM + Cox loop (optional)\n",
    "# =========================\n",
    "time_col, event_col, endpoint = find_time_event_cols(df)\n",
    "km_rows = []\n",
    "\n",
    "if time_col is None:\n",
    "    print(\"[INFO] No time-to-event columns detected; skip KM/Cox.\")\n",
    "else:\n",
    "    km_df = df.copy()\n",
    "    km_df[event_col] = km_df[event_col].apply(to_event01)\n",
    "    km_df[time_col] = pd.to_numeric(km_df[time_col], errors=\"coerce\")\n",
    "    km_df = km_df.dropna(subset=[time_col, event_col]).copy()\n",
    "    km_df[event_col] = km_df[event_col].astype(int)\n",
    "\n",
    "    print(f\"[INFO] Using endpoint={endpoint} | time_col={time_col} | event_col={event_col}\")\n",
    "    print(\"KM usable samples:\", km_df.drop_duplicates([\"sample\"]).shape[0])\n",
    "\n",
    "    for (unit, strategy, which), g in km_df.groupby(group_cols):\n",
    "        gg = g.sort_values(\"sample\").drop_duplicates(subset=[\"sample\"])\n",
    "        if len(gg) < 10:\n",
    "            km_rows.append({\n",
    "                \"unit\": unit, \"strategy\": strategy, \"which\": which,\n",
    "                \"endpoint\": endpoint, \"n\": int(len(gg)),\n",
    "                \"events\": int(gg[event_col].sum()),\n",
    "                \"median_cut\": np.nan,\n",
    "                \"logrank_p\": np.nan,\n",
    "                \"cox_hr_log1p\": np.nan, \"cox_ci_low\": np.nan, \"cox_ci_high\": np.nan, \"cox_p\": np.nan,\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # median split\n",
    "        median_val = gg[\"tnb_value\"].median()\n",
    "        gg = gg.copy()\n",
    "        gg[\"group\"] = np.where(gg[\"tnb_value\"] > median_val, \"High\", \"Low\")\n",
    "\n",
    "        gH = gg[gg[\"group\"] == \"High\"]\n",
    "        gL = gg[gg[\"group\"] == \"Low\"]\n",
    "        if len(gH) < 3 or len(gL) < 3:\n",
    "            km_rows.append({\n",
    "                \"unit\": unit, \"strategy\": strategy, \"which\": which,\n",
    "                \"endpoint\": endpoint, \"n\": int(len(gg)),\n",
    "                \"events\": int(gg[event_col].sum()),\n",
    "                \"median_cut\": float(median_val),\n",
    "                \"logrank_p\": np.nan,\n",
    "                \"cox_hr_log1p\": np.nan, \"cox_ci_low\": np.nan, \"cox_ci_high\": np.nan, \"cox_p\": np.nan,\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # log-rank\n",
    "        lr = logrank_test(\n",
    "            gH[time_col], gL[time_col],\n",
    "            event_observed_A=gH[event_col],\n",
    "            event_observed_B=gL[event_col],\n",
    "        )\n",
    "\n",
    "        # KM plot\n",
    "        kmf = KaplanMeierFitter()\n",
    "        plt.figure(figsize=(6.8, 5.6))\n",
    "\n",
    "        kmf.fit(gL[time_col], event_observed=gL[event_col], label=f\"Low (n={len(gL)})\")\n",
    "        ax = kmf.plot(ci_show=True)\n",
    "        kmf.fit(gH[time_col], event_observed=gH[event_col], label=f\"High (n={len(gH)})\")\n",
    "        kmf.plot(ax=ax, ci_show=True)\n",
    "\n",
    "        plt.xlabel(f\"Time (weeks) [{endpoint}]\")\n",
    "        plt.ylabel(\"Survival probability\")\n",
    "        plt.title(f\"[{COHORT_LABEL}] {unit}-{strategy}-{which}\\nlog-rank p={lr.p_value:.3g} (median={median_val:.3g})\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if SAVE_PLOTS:\n",
    "            fn = safe_filename(f\"KM_{COHORT_LABEL}_{endpoint}_{unit}_{strategy}_{which}.png\")\n",
    "            plt.savefig(os.path.join(OUTDIR, fn), dpi=200)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "        # Cox continuous: log1p(tnb)\n",
    "        cox_df = gg[[time_col, event_col, \"tnb_value\"]].copy()\n",
    "        cox_df[\"x\"] = np.log1p(cox_df[\"tnb_value\"].astype(float))\n",
    "\n",
    "        cph = CoxPHFitter()\n",
    "        cph.fit(cox_df[[time_col, event_col, \"x\"]], duration_col=time_col, event_col=event_col)\n",
    "        summ = cph.summary.loc[\"x\", [\"exp(coef)\", \"exp(coef) lower 95%\", \"exp(coef) upper 95%\", \"p\"]]\n",
    "\n",
    "        hr = float(summ[\"exp(coef)\"])\n",
    "        lo = float(summ[\"exp(coef) lower 95%\"])\n",
    "        hi = float(summ[\"exp(coef) upper 95%\"])\n",
    "        p = float(summ[\"p\"])\n",
    "\n",
    "        km_rows.append({\n",
    "            \"unit\": unit, \"strategy\": strategy, \"which\": which,\n",
    "            \"endpoint\": endpoint, \"n\": int(len(gg)),\n",
    "            \"events\": int(gg[event_col].sum()),\n",
    "            \"median_cut\": float(median_val),\n",
    "            \"logrank_p\": float(lr.p_value),\n",
    "            \"cox_hr_log1p\": hr, \"cox_ci_low\": lo, \"cox_ci_high\": hi, \"cox_p\": p,\n",
    "        })\n",
    "\n",
    "    km_summary = pd.DataFrame(km_rows).sort_values([\"cox_p\"])\n",
    "    km_summary.to_csv(\"/work/longyh/BY/processed/TNB/km_cox_summary_long.csv\", index=False)\n",
    "    print(\"Saved: km_cox_summary_long.csv\")\n",
    "    print(km_summary.head(20))\n",
    "\n",
    "\n",
    "print(\"Done. Plots saved to:\", OUTDIR)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
